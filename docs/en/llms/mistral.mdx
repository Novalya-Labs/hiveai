---
title: "Mistral AI"
description: "Using Mistral models in HiveAI"
---

# Mistral AI

Use Mistral models for cost-effective, fast inference.

## Configuration

```yaml
llm:
  provider: mistral
  model: mistral-large-latest
  temperature: 0.7
  max_tokens: 1500
```

## Models

| Model | Best For |
|-------|----------|
| mistral-large-latest | Complex tasks |
| mistral-medium | Balanced |
| mistral-small | Fast, cheap |

## API Key

```bash
# .env
MISTRAL_API_KEY=...
```

Get your key: [console.mistral.ai](https://console.mistral.ai)

## Function Calling

Full support for Mistral function calling.
